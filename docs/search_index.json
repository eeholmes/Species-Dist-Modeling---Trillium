[
["index.html", "SDMs - Trillium Example Overview 0.1 Prequisite knowledge 0.2 Set-up - R and RStudio 0.3 Get the shapefiles for Hubbard Brook 0.4 Set-up - R packages 0.5 Data downloads", " SDMs - Trillium Example E. E. Holmes 2020-08-03 Overview A project to learn how to do species distribution modeling (SDM) in R. Ultimately, I’ll use the biomod2 package but in the learning phase, I am running models without it. 0.1 Prequisite knowledge Before going through the code, you should have a basic understanding of spatial data and working with that data in R. The spatial manipulations done here are super simple but if you have no or very little exposure to spatial data terminology or the raster package in R, then go through this chapter on spatial data in R first. 0.2 Set-up - R and RStudio If you have not updated R recently (in the last 6 months), go ahead and do that. Also update RStudio is you haven’t done that recently. Download R here Download RStudio here 0.3 Get the shapefiles for Hubbard Brook Create a project in RStudio for the SDM building. Within that project, create a folder called data and one called code. Within data create a folder called hbef_boundary. Go to the Species-Dist-Modeling—Trillium repository hbef_boundary folder and download all the files there into your hbef_boundary folder. 0.4 Set-up - R packages The code will use the following R packages which you will need to install. Open RStudio and go to the Packages tab on the right. Then click Install and search for the package. library(biomod2) library(dismo) library(sp) library(raster) library(ggplot2) library(maps) library(usdm) library(ecospat) library(corrplot) library(MASS) library(gam) library(stringr) # for easy string manipulation library(tidyr) # for data wrangling for ggplot library(knitr) # for R Markdown library(here) # for intelligent file directory navigation 0.5 Data downloads When you go through the Rmd files, it will download a lot of data into your project, but the next time you run the files, the code will look for the downloaded files and not rerun the downloads. "],
["trillium.html", "Chapter 1 Trillium", " Chapter 1 Trillium Trillium genus are long-lived, woodland, perennial wildflower found throughout eastern North America. In this example, I have temperature, precipitation and basic land cover data. I will use that to try to model Trillium distribution. Trillium grandiflorum occurs on well-drained, rich, mesic soils in deciduous or mixed deciduous/coniferous forests. Trillium undulatum occurs in mesic, northern hardwoods, mixed conifer-hardwood forests, to pinewoods and high-elevation red spruce forests in very acidic humus-rich soils. Red Trillium Painted Trillium Hubbard Brook is an experimental forest in New Hampshire. It is in a watershed surrounded by a ridge with Hubbard Brook flowing west to east. There are few Trillium observations in the GBIF database in the experimental forest though Trillium occurs there. "],
["shape-files.html", "Chapter 2 Shape files 2.1 Create the boundary box 2.2 Get the states shapefile 2.3 Get the Hubbard Brook boundary 2.4 Plot the boundaries together 2.5 Save", " Chapter 2 Shape files The first step is to define the spatial extent of the area you will be working with and set up any shape files you need to plot boundaries or polygons or mask out areas. library(sp) library(raster) library(maps) 2.1 Create the boundary box First I need to define an raster::extent object for a box bounding NH and VT. This will be used to crop the data that we download. I can get a bounding box dynamically using drawExtent(). Click twice (upper corner/lower corner) on the map to select the region of interest. Don’t go too far outside the lines. maps::map(&quot;state&quot;, region = c(&quot;new hampshire&quot;, &quot;vermont&quot;, &quot;new york&quot;, &quot;massachusetts&quot;)) NHVT &lt;- raster::drawExtent() or I can use longitude/latitude values for the box and use extent(): NHVT &lt;- raster::extent(-73.61056, -70.60205, 42.48873, 45.37969) 2.2 Get the states shapefile I download the shapefile for the NH and VT state borders using getData() which gives polygons for countries. Level 1 will be the state boundaries (I assume). The shape file has all the states. Then I use subset() to get the two states that I want. path says where to save the downloaded file. usashp &lt;- raster::getData(&quot;GADM&quot;, country = &quot;USA&quot;, level = 1, path = &quot;data&quot;) nhvtshp &lt;- subset(usashp, NAME_1 %in% c(&quot;New Hampshire&quot;, &quot;Vermont&quot;)) nhshp &lt;- subset(usashp, NAME_1 %in% c(&quot;New Hampshire&quot;)) vtshp &lt;- subset(usashp, NAME_1 %in% c(&quot;Vermont&quot;)) Check the projection for this shapefile: crs(nhvtshp) CRS arguments: +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 I can plot the shapes. plot(nhvtshp, border = &quot;blue&quot;, axes = TRUE) 2.3 Get the Hubbard Brook boundary I downloaded this shapefile separately and read it in. This will get the boundary of the Hubbard Brook Experimental Forest from a shapefile. Although I write “shapefile” singular, it is actually two files, the shapefile and some metafiles. If you look in the hbef_boundary folder you’ll the metafiles. hbshp &lt;- raster::shapefile(&quot;data/hbef_boundary/hbef_boundary.shp&quot;) I check its projection and note that it is different from the NH+VT shapefile. crs(hbshp) CRS arguments: +proj=utm +zone=19 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs I transform the shapefile to get it on the same projection. newcrs &lt;- crs(nhvtshp) hbshp &lt;- sp::spTransform(hbshp, newcrs) Plot it. plot(hbshp) 2.4 Plot the boundaries together plot(nhvtshp, border = &quot;blue&quot;, axes = TRUE) plot(hbshp, add = TRUE) text(-71.8, 44, &quot;HBEF&quot;, pos = 4) 2.5 Save I save the shapefile data to a file so I can use it later without rerunning this code. save(nhvtshp, hbshp, nhshp, vtshp, NHVT, file = &quot;data/shapefiles.RData&quot;) "],
["observation-data.html", "Chapter 3 Observation data 3.1 Set-up 3.2 Download data 3.3 Check the coordinate projection 3.4 Make a sp object 3.5 Check for inaccurate location data 3.6 Plot 3.7 Save", " Chapter 3 Observation data 3.1 Set-up This example will use the following libraries: library(dismo) library(sp) library(here) Load the shapefiles created earlier. load(&quot;data/shapefiles.RData&quot;) 3.2 Download data I will download occurrence data for Trillium grandiflorum and Trillium undulatum in my NHVT bounding box from the Global Biodiversity Information Facility. nrecs seems to be ignored. geo means only points with longitude and latitude. removeZeros means get rid of NA in location. ext is the bounding box to use. First I set where I will save the file and check if it is already there. I do this because if I rerun this script, I don’t want to re-download. Note that GBIF data is updated weekly so using a time-stamp on your file might be good, but I am not doing that for this example. filePath &lt;- file.path(here::here(), &quot;data/trillium_presences.RData&quot;) Now I download if I haven’t downloaded already. The downloaded data has many columns that I don’t need. I will subset the following columns. select in the subset() call says what columns to use. if (!file.exists(filePath)) { # Download grandiflorum &lt;- dismo::gbif(&quot;Trillium&quot;, species = &quot;grandiflorum&quot;, nrecs = 300, geo = TRUE, removeZeros = TRUE, ext = NHVT) undulatum &lt;- dismo::gbif(&quot;Trillium&quot;, species = &quot;undulatum&quot;, nrecs = 300, geo = TRUE, removeZeros = TRUE, ext = NHVT) trillium.raw &lt;- rbind(grandiflorum, undulatum) # select columns colsWeNeed &lt;- c(&quot;species&quot;, &quot;lat&quot;, &quot;lon&quot;, &quot;locality&quot;, &quot;year&quot;, &quot;coordinateUncertaintyInMeters&quot;, &quot;occurrenceID&quot;, &quot;occurrenceRemarks&quot;, &quot;geodeticDatum&quot;) trillium.raw &lt;- subset(trillium.raw, select = colsWeNeed) save(trillium.raw, file = &quot;data/trillium_presences.RData&quot;) } Load in the presences data (saved from code above). load(&quot;data/trillium_presences.RData&quot;) 3.3 Check the coordinate projection Check the projection to make sure it makes sense and there is only one value. Check that it is the same projection as my other layers. unique(trillium.raw$geodeticDatum) # &#39;WGS84&#39; [1] &quot;WGS84&quot; 3.4 Make a sp object trillium.raw is just a data frame. I make it a sp object (specifically a SpatialPointsDataFrame) using sp::coordinates() to specify which columns are the longitude and latitude. trillium &lt;- trillium.raw sp::coordinates(trillium) &lt;- c(&quot;lon&quot;, &quot;lat&quot;) Check that it looks ok and there are no NAs. summary(trillium$lon) Min. 1st Qu. Median Mean 3rd Qu. Max. -73.58 -73.04 -72.64 -72.44 -71.89 -70.61 summary(trillium$lat) Min. 1st Qu. Median Mean 3rd Qu. Max. 42.49 43.67 44.21 44.04 44.48 45.37 3.5 Check for inaccurate location data The coordinateUncertaintyInMeters column give the uncertainty of the observation location. Some of the uncertainties are huge and I don’t want those. table(cut(trillium$coordinateUncertaintyInMeters, c(0, 200, 500, 1000, 2000, 5000))) (0,200] (200,500] (500,1e+03] (1e+03,2e+03] (2e+03,5e+03] 1230 81 39 48 60 I am going to keep only those locations with a location accuracy within 200m. good &lt;- which(trillium$coordinateUncertaintyInMeters &lt; 200) trillium &lt;- trillium[good, ] 3.6 Plot Now I can plot the occurrences points and add the NH and VT state boundaries. Trillium undulatum is much more common. Hubbard Brook is outlined in blue. plot(nhvtshp, border = &quot;blue&quot;, axes = TRUE) plot(subset(trillium, species == &quot;Trillium grandiflorum&quot;), pch = 3, cex = 1, add = TRUE) plot(subset(trillium, species == &quot;Trillium undulatum&quot;), pch = 4, cex = 1, col = &quot;red&quot;, add = TRUE) plot(hbshp, add = TRUE, border = &quot;blue&quot;) 3.7 Save I will save to the trillium file also. Later I will be subsetting and using a grid with pa=1 if trillium was observed in that grid cell so I want to name it to be clear that this is the original observance data. trillium_observed &lt;- trillium save(trillium, trillium.raw, file = &quot;data/trillium_presences.RData&quot;) "],
["variables.html", "Chapter 4 Variables 4.1 Set-up 4.2 Climatic data 4.3 Topographical data 4.4 Land cover data 4.5 Stack all variables 4.6 Fix layer names 4.7 Fix temperature in GBIF 4.8 Save", " Chapter 4 Variables I will download climate, landcover and elevation data to use as predictors. 4.1 Set-up This chapter will use the following libraries. These must be loaded for the code in this chapter to work. I’ve used :: to clarify what functions are associated with what packages, but still the packages must be loaded to do any plotting. library(sp) library(raster) library(stringr) I need to load in the shapefile data from Chapter 1. load(&quot;data/shapefiles.RData&quot;) I have found that when working with large raster layers that RStudio can sometimes get very slow. In that case a call to the “garbage collection” gc() function to clear out temporary memory can help. If it doesn’t then going to the Tools tab and restarting R will help. The latter will get rid of any variables in your working directory so make sure anything you need is saved. 4.2 Climatic data I will use the getData function from the raster package to get climate data. I will retrieve global bioclimatic variables at 0.5’ (1km) resolution from WorldClim. This returns 19 bioclimatic variables. For the 0.5’ resolution, I need to give it a center longitude and latitude and then it returns data centered on that in a 30 degrees longitude and latitude box. This is 300+ Mb but it will check if the directory exists and won’t keep re downloading if you re-run the code. path tells it where to save the downloaded directory (which will be called wc0.5). bioclimVars &lt;- raster::getData(name = &quot;worldclim&quot;, res = 0.5, var = &quot;bio&quot;, lon = mean(NHVT[1:2]), lat = mean(NHVT[3:4]), path = &quot;data&quot;) bioclimVars is a raster stack. class(bioclimVars) A raster stack is collection of many raster layers with the same projection, spatial extent and resolution. I don’t know why _13 is appended to the bioclim names by getData(). raster::extent(bioclimVars) # lons are x and lats are y class : Extent xmin : -90 xmax : -60 ymin : 30 ymax : 60 names(bioclimVars) # look at the variable names [1] &quot;bio1_13&quot; &quot;bio2_13&quot; &quot;bio3_13&quot; &quot;bio4_13&quot; &quot;bio5_13&quot; &quot;bio6_13&quot; [7] &quot;bio7_13&quot; &quot;bio8_13&quot; &quot;bio9_13&quot; &quot;bio10_13&quot; &quot;bio11_13&quot; &quot;bio12_13&quot; [13] &quot;bio13_13&quot; &quot;bio14_13&quot; &quot;bio15_13&quot; &quot;bio16_13&quot; &quot;bio17_13&quot; &quot;bio18_13&quot; [19] &quot;bio19_13&quot; 4.2.1 Crop and subset I will crop down this raster stack to the NH+VT bounding box. NHVTVars &lt;- raster::crop(bioclimVars, NHVT) Here I will plot just 3 of these variables. BIO10 = Mean Temperature of Warmest Quarter BIO15 = Precipitation Seasonality (how much precipitation varies during year) BIO19 = Precipitation of Coldest Quarter sub.NHVTVars &lt;- subset(NHVTVars, c(&quot;bio10_13&quot;, &quot;bio15_13&quot;, &quot;bio19_13&quot;)) Plot these three variables. This takes awhile. Note bio10_13 is mean temperature times 10. That’s how GBIF records temperature. plot(sub.NHVTVars) Another why to make this stack is to read in the data from the downloaded files in dir(\"wc0.5\"). Downloaded in .bil format and comprised of two files. fils &lt;- dir(&quot;data/wc0.5&quot;, full.names = TRUE) fils &lt;- fils[stringr::str_detect(fils, &quot;bil&quot;)] Plot one layer. onelayer &lt;- raster::raster(fils[1]) plot(onelayer, xlim = NHVT[1:2], ylim = NHVT[3:4]) # Add the NH VT lines on top plot(nhvtshp, add = TRUE, border = &quot;blue&quot;) plot(hbshp, add = TRUE) title(names(onelayer)) You can create a stack from the file names and then crop to the NH+VT bounding box. # But for some reason when it reads in the bil file, it is # not setting the projection from the header file. So I&#39;ll # use the NHVTVars &lt;- raster::stack(fils) NHVTVars &lt;- raster::crop(NHVTVars, NHVT) 4.2.2 Bioclim names I want to make a data frame to use to get the descriptions for the variables. I made this by looking at the WorldClim website. name is the name of the variable in the downloaded data, desc is a description, col is what I will call the column. bioclimnames &lt;- data.frame(name = paste0(&quot;bio&quot;, 1:19, &quot;_13&quot;), desc = c(&quot;Mean annual temperature&quot;, &quot;Mean diurnal range (mean of max temp - min temp)&quot;, &quot;Isothermality (bio2/bio7) (* 100)&quot;, &quot;Temperature seasonality (standard deviation *100)&quot;, &quot;Max temperature of warmest month&quot;, &quot;Min temperature of coldest month&quot;, &quot;Temperature annual range (bio5-bio6)&quot;, &quot;Mean temperature of the wettest quarter&quot;, &quot;Mean temperature of driest quarter&quot;, &quot;Mean temperature of warmest quarter&quot;, &quot;Mean temperature of coldest quarter&quot;, &quot;Total (annual) precipitation&quot;, &quot;Precipitation of wettest month&quot;, &quot;Precipitation of driest month&quot;, &quot;Precipitation seasonality (coefficient of variation)&quot;, &quot;Precipitation of wettest quarter&quot;, &quot;Precipitation of driest quarter&quot;, &quot;Precipitation of warmest quarter&quot;, &quot;Precipitation of coldest quarter&quot;), col = c(&quot;mean.temp&quot;, &quot;temp.diurnal.range&quot;, &quot;isotherm&quot;, &quot;temp.seasonality&quot;, &quot;max.warm.temp&quot;, &quot;min.cold.temp&quot;, &quot;temp.annual.range&quot;, &quot;mean.temp.wet.qtr&quot;, &quot;mean.temp.dry.qtr&quot;, &quot;mean.temp.warm.qtr&quot;, &quot;mean.temp.cold.qtr&quot;, &quot;total.precip&quot;, &quot;precip.wet.month&quot;, &quot;precip.dry.month&quot;, &quot;precip.seasonality&quot;, &quot;precip.wet.qtr&quot;, &quot;precip.dry.qtr&quot;, &quot;precip.warm.qtr&quot;, &quot;precip.cold.qtr&quot;), stringsAsFactors = FALSE) Do some memory clean-up before moving on. gc() used (Mb) gc trigger (Mb) limit (Mb) max used (Mb) Ncells 4212980 225.0 7810815 417.2 NA 7683620 410.4 Vcells 10727831 81.9 20676752 157.8 16384 20674865 157.8 4.3 Topographical data I can read in elevation data with getData(). For USA, this returns a list of 4 raster layers. List 1 is mainland. Then I crop to my NHVT bounding box. I don’t need to re-download the data if I already have it. path is the folder where the downloaded data will be stored. mask=FALSE means don’t cut off the elevation data at the US-Canada border. The USAelevation object is about 80MB. That is not needed so you might not want to save that file. dirPath &lt;- &quot;data/elevation&quot; if (!dir.exists(dirPath)) dir.create(dirPath) if (!file.exists(&quot;data/NHVTelevation.grd&quot;)) { USAelevation &lt;- raster::getData(&quot;alt&quot;, country = &quot;USA&quot;, path = &quot;data/elevation&quot;, mask = FALSE) raster::writeRaster(USAelevation[[1]], filename = &quot;data/USAelevation.grd&quot;, overwrite = TRUE) NHVT.elevation &lt;- raster::crop(USAelevation[[1]], NHVT) raster::writeRaster(NHVT.elevation, filename = &quot;data/NHVTelevation.grd&quot;, overwrite = TRUE) } else { NHVT.elevation &lt;- raster::raster(&quot;data/NHVTelevation.grd&quot;) } The plot of raw elevation is not so pretty. Later we will use the hillshade() function to make a nicer plot of elevation. plot(NHVT.elevation, axes = TRUE, legend.args = list(text = &quot;elevation (m)&quot;, adj = 0.2)) 4.3.1 Slope and aspect The terrain() function will return the slope and aspect from an elevation layer. NHVT.slope &lt;- raster::terrain(NHVT.elevation, opt = &quot;slope&quot;) NHVT.aspect &lt;- raster::terrain(NHVT.elevation, opt = &quot;aspect&quot;) Plot of aspect. plot(NHVT.aspect) plot(nhvtshp, add = TRUE) There is also a hillShade() function that makes a prettier elevation plot than the elevation data alone. hill &lt;- raster::hillShade(NHVT.slope, NHVT.aspect, 40, 270) plot(hill, col = grey(0:100/100), legend = FALSE, main = &quot;NH and VT elevation&quot;) plot(NHVT.elevation, col = rainbow(25, alpha = 0.35), add = TRUE) plot(nhvtshp, add = TRUE) plot(hbshp, add = TRUE) 4.4 Land cover data These data are downloaded from EarthEnv land cover data set with a function called getlandcover.R in the code folder. fils &lt;- paste0(&quot;data/landcover/lc_1km_&quot;, c(1:12, &quot;dom&quot;), &quot;.tif&quot;) # check if the files already exist, and if not, download if (!all(file.exists(fils))) { getlandcover(gisdir = &quot;data/landcover&quot;, ext = NHVT) } NHVT.landcover &lt;- raster::stack(fils) The names are cryptic. Fix that. oldnames &lt;- paste0(&quot;lc_1km_&quot;, c(1:12, &quot;dom&quot;)) newnames &lt;- c(&quot;Mixed.Needleleaf.Trees&quot;, &quot;Evergreen.Broadleaf.Trees&quot;, &quot;Deciduous.Broadleaf.Trees&quot;, &quot;Mixed.Other.Trees&quot;, &quot;Shrubs&quot;, &quot;Herbaceous&quot;, &quot;Cultivated&quot;, &quot;Flooded&quot;, &quot;Urban&quot;, &quot;Snow&quot;, &quot;Barren&quot;, &quot;Water&quot;, &quot;Dominant.Land.Cover&quot;) names(NHVT.landcover)[match(names(NHVT.landcover), oldnames)] &lt;- newnames I want to make a layer for trees which are in layers 1 to 4. for (i in 1:4) { fil &lt;- paste0(&quot;data/landcover/lc_1km_&quot;, i, &quot;.tif&quot;) r &lt;- raster(fil) if (i == 1) rt &lt;- r else rt &lt;- r + rt } NHVT.Trees &lt;- rt names(NHVT.Trees) &lt;- &quot;Tree.Cover&quot; Trillium undulatum is associated with tree cover. plot(NHVT.Trees) plot(nhvtshp, add = TRUE, border = &quot;blue&quot;) plot(hbshp, add = TRUE) title(&quot;Tree Cover&quot;) plot(subset(trillium, species == &quot;Trillium undulatum&quot;), pch = &quot;.&quot;, cex = 2, col = &quot;red&quot;, add = TRUE) plot(hbshp, add = TRUE, border = &quot;blue&quot;) 4.5 Stack all variables First, I will create a stack with all my variables. allVars &lt;- raster::stack(NHVTVars, NHVT.elevation, NHVT.slope, NHVT.aspect, NHVT.landcover, NHVT.Trees) 4.6 Fix layer names The names in allVars are annoying, so I’ll give it better names. names(allVars) [1] &quot;bio1_13&quot; &quot;bio2_13&quot; [3] &quot;bio3_13&quot; &quot;bio4_13&quot; [5] &quot;bio5_13&quot; &quot;bio6_13&quot; [7] &quot;bio7_13&quot; &quot;bio8_13&quot; [9] &quot;bio9_13&quot; &quot;bio10_13&quot; [11] &quot;bio11_13&quot; &quot;bio12_13&quot; [13] &quot;bio13_13&quot; &quot;bio14_13&quot; [15] &quot;bio15_13&quot; &quot;bio16_13&quot; [17] &quot;bio17_13&quot; &quot;bio18_13&quot; [19] &quot;bio19_13&quot; &quot;USA1_alt&quot; [21] &quot;slope&quot; &quot;aspect&quot; [23] &quot;Mixed.Needleleaf.Trees&quot; &quot;Evergreen.Broadleaf.Trees&quot; [25] &quot;Deciduous.Broadleaf.Trees&quot; &quot;Mixed.Other.Trees&quot; [27] &quot;Shrubs&quot; &quot;Herbaceous&quot; [29] &quot;Cultivated&quot; &quot;Flooded&quot; [31] &quot;Urban&quot; &quot;Snow&quot; [33] &quot;Barren&quot; &quot;Water&quot; [35] &quot;Dominant.Land.Cover&quot; &quot;Tree.Cover&quot; I will write code to assign the right names. That way I won’t risk giving the wrong names to columns. # these are the annoying names oldcols &lt;- c(bioclimnames$name, &quot;USA1_alt&quot;) # better names newcols &lt;- c(bioclimnames$col, &quot;elevation&quot;) for (i in 1:length(oldcols)) names(allVars)[names(allVars) == oldcols[i]] &lt;- newcols[i] 4.7 Fix temperature in GBIF The temperature returned by GBIF is temperature x 10 so I will fix that. for (i in names(allVars)[stringr::str_detect(names(allVars), &quot;temp&quot;)]) { allVars[[i]] &lt;- allVars[[i]]/10 } 4.8 Save Finally, I will save allVars the stack of raster layers to a file. rf &lt;- raster::writeRaster(allVars, filename = &quot;data/allVars.grd&quot;, overwrite = TRUE) Plot. I use rf here because raster layers are associated with files on disk which need to be read. R Markdown doesn’t like reading from the temporary files sometimes. By using rf I direct it to use the data/allVars.grd file not a temporary file. plot(rf) "],
["sdm-data-frame.html", "Chapter 5 SDM Data Frame 5.1 Set-up 5.2 Variable values for presences 5.3 Background points 5.4 Make final data frame 5.5 Save", " Chapter 5 SDM Data Frame 5.1 Set-up This example will use the following libraries: library(raster) Load the shapefiles, Trillium data and variables raster stack created earlier. load(&quot;data/shapefiles.RData&quot;) load(&quot;data/trillium_presences.RData&quot;) allVars &lt;- raster::brick(&quot;data/allVars.grd&quot;) 5.2 Variable values for presences For fitting an SDM, I need a data frame where each row is a grid cell (in my NHVT raster) where the species has been observed (so presence = 1) and I have the variable value for that cell in the other columns. So the idea is to get the variable values for each of these observations. plot(nhvtshp, border = &quot;blue&quot;, axes = TRUE) plot(subset(trillium, species == &quot;Trillium grandiflorum&quot;), pch = 3, cex = 1, add = TRUE) plot(subset(trillium, species == &quot;Trillium undulatum&quot;), pch = 4, cex = 1, col = &quot;red&quot;, add = TRUE) plot(hbshp, add = TRUE, border = &quot;blue&quot;) EXCEPT that the variable data is on a grid while the observation data is points with lat/lon values. What I need is a data frame where each row is a grid cell where Trillium was observed (either once or many times) and the variable values for that cell. The following code gets you to that data frame. 5.2.1 Get the variable data I can create a data frame with the values of the variables where Trillium locations are using the extract() function. This will take a lat/lon value, figure out what cell that lat/lon pair is in, and return the variable values for that cell. The function takes a raster layer or stack of layers and the point location data (as a spatial points object) and returns the values for each layer in a column. I use cellnumbers=TRUE to return what cell that lat/lon pair is in. This will allow me to eliminate duplicates (observations from the same cell). trillVars &lt;- data.frame(raster::extract(allVars, trillium, cellnumbers = TRUE)) 5.2.2 Add on the species, pa, and lon/lat info I add on columns for the species name and “presence-absence”. trillVars$species &lt;- trillium$species trillVars$pa &lt;- 1 trillVars$lon &lt;- raster::xFromCell(r, trillVars$cells) trillVars$lat &lt;- raster::yFromCell(r, trillVars$cells) These are for grid cells. For later plotting, I might want the center of the cells so I’ll add that on. trillVars$lon &lt;- raster::xFromCell(r, trillVars$cells) trillVars$lat &lt;- raster::yFromCell(r, trillVars$cells) 5.2.3 Check for duplicates Duplicates means multiple occurrences assigned to the same cell. We can find this by seeing how many values in the cells column are duplicates. There are many. Our raster cells are 0.5 x 0.5 degrees (so 1km or so?). Trillium occurrences in that same cell (lat/lon values that are in the same 0.5 square grid) will have the same cell number so will be “duplicates”, meaning an occurrence in a cell where there is already another occurrence. # this is where both cell and species are the same dups &lt;- duplicated(cbind(trillVars$cells, trillVars$species)) sum(dups) [1] 478 I get rid of them by saying take the non-duplicated cell values. trillVars &lt;- trillVars[!dups, ] Now I have about half the number of lines of data. dim(trillVars) [1] 750 41 5.3 Background points SDMs for presence only data need a set of samples from the background area where it is possible that the species could have been observed. Technically, we’d want to weight this background by where searching was more likely or at least remove regions where it is impossible to observe the species. Trillium won’t be observed in urban areas and water bodies so we might want to create a mask of impossible areas not include background from there. But to keep things simple, for now I’ll just sample randomly from my NHVT bounding box. I will add on 5000 random background points by sampling from all the cells in allVars. I want to keep the lon/lat information (cell centers in this case). background &lt;- data.frame(raster::sampleRandom(allVars, size = 5000, cells = TRUE, xy = TRUE)) I need to fix the first three column names since I will be appending this data frame to the one above and that one uses cells as the cell column name. Also add on species name and presence-absence info. names(background)[1:3] &lt;- c(&quot;cells&quot;, &quot;lon&quot;, &quot;lat&quot;) background$pa &lt;- 0 To make it easier to create my training and testing datasets for the two species, I make two copies of the background with a different species value for each. background &lt;- rbind(background, background) background$species &lt;- c(rep(&quot;Trillium grandiflorum&quot;, 5000), rep(&quot;Trillium undulatum&quot;, 5000)) In order to bind this data frame to the presence one, I need the column names to also be in the same order. I need to fix that since sampleRandom() put the lat/lon columns in columns 2 and 3. The first line of code is selecting columns from background in the order shown after the , then I check that I did it right and the colnames are identical background &lt;- background[, colnames(trillVars)] identical(colnames(background), colnames(trillVars)) [1] TRUE 5.4 Make final data frame Now I bind this two data frames together for final data frame with occurrences, climatic data, and my background zeros. dat &lt;- rbind(trillVars, background) The rownames are annoying so I will set to NULL. rownames(dat) &lt;- NULL Now I have my final data frame with the following column names. colnames(dat) [1] &quot;cells&quot; &quot;mean.temp&quot; [3] &quot;temp.diurnal.range&quot; &quot;isotherm&quot; [5] &quot;temp.seasonality&quot; &quot;max.warm.temp&quot; [7] &quot;min.cold.temp&quot; &quot;temp.annual.range&quot; [9] &quot;mean.temp.wet.qtr&quot; &quot;mean.temp.dry.qtr&quot; [11] &quot;mean.temp.warm.qtr&quot; &quot;mean.temp.cold.qtr&quot; [13] &quot;total.precip&quot; &quot;precip.wet.month&quot; [15] &quot;precip.dry.month&quot; &quot;precip.seasonality&quot; [17] &quot;precip.wet.qtr&quot; &quot;precip.dry.qtr&quot; [19] &quot;precip.warm.qtr&quot; &quot;precip.cold.qtr&quot; [21] &quot;elevation&quot; &quot;slope&quot; [23] &quot;aspect&quot; &quot;Mixed.Needleleaf.Trees&quot; [25] &quot;Evergreen.Broadleaf.Trees&quot; &quot;Deciduous.Broadleaf.Trees&quot; [27] &quot;Mixed.Other.Trees&quot; &quot;Shrubs&quot; [29] &quot;Herbaceous&quot; &quot;Cultivated&quot; [31] &quot;Flooded&quot; &quot;Urban&quot; [33] &quot;Snow&quot; &quot;Barren&quot; [35] &quot;Water&quot; &quot;Dominant.Land.Cover&quot; [37] &quot;Tree.Cover&quot; &quot;species&quot; [39] &quot;pa&quot; &quot;lon&quot; [41] &quot;lat&quot; 5.5 Save I save the data frame. dat is a non-descriptive name and a little dangerous to use since the user might have dat already in their working environment. I will also make dat.und and dat.grand for the two Trillium species. There are some NAs in the slope aspect data which I will get rid of. dat.und &lt;- subset(dat, species == &quot;Trillium undulatum&quot;) dat.und &lt;- na.omit(dat.und) dat.grand &lt;- subset(dat, species == &quot;Trillium grandiflorum&quot;) dat.grand &lt;- na.omit(dat.grand) Save. save(dat, dat.und, dat.grand, file = &quot;data/trillium_with_predictors.RData&quot;) "],
["variable-correlation.html", "Chapter 6 Variable Correlation 6.1 Set-up 6.2 Variable correlation 6.3 Variance Inflation Factor 6.4 Save", " Chapter 6 Variable Correlation Including variables that are highly correlated is a big problem when doing regression analyses. You will get pairs of highly positive and negative effect size estimates and huge standard errors on your estimates. So we need to evaluate correlation and select a set of variables that is not terribly correlated. This example will use the following libraries. library(corrplot) library(usdm) library(stringr) library(raster) 6.1 Set-up Load the data prepared in earlier chapters. This loads dat.und with the climate data for each cell with presences of Trillium undulatum plus the background cells. load(&quot;data/trillium_with_predictors.RData&quot;) There are a few covariates that I know I don’t want. Specifically, the wet and dry qtr variables because that is summer in some cells and winter in others. Also I’ll exclude Snow, since that is all 0. And I’ll exclude cells and species since I don’t use those ever. Finally, dominant land cover is a categorical variable so I will exclude that (to make my life easier). dat.und &lt;- dat.und[, !stringr::str_detect(colnames(dat.und), &quot;[.]wet[.]&quot;)] dat.und &lt;- dat.und[, !stringr::str_detect(colnames(dat.und), &quot;[.]dry[.]&quot;)] dat.und &lt;- subset(dat.und, select = c(-cells, -species, -Dominant.Land.Cover, -Snow)) 6.2 Variable correlation First I will use the corrplot package to look at correlation visually. tmpdat &lt;- subset(dat.und, select = stringr::str_detect(colnames(dat.und), &quot;precip&quot;)) varCor &lt;- cor(tmpdat, use = &quot;na.or.complete&quot;) corrplot::corrplot(varCor) Many of the temperature variables are very correlated. tmpdat &lt;- subset(dat.und, select = stringr::str_detect(colnames(dat.und), &quot;temp&quot;)) varCor &lt;- cor(tmpdat, use = &quot;na.or.complete&quot;) corrplot::corrplot(varCor) After exploring the models, I came up with the following set of not too correlated variables that still explain much of the variability in presence/absence. But below I will also try variance inflation to select a set of non-collinear variables. envvars &lt;- c(&quot;mean.temp&quot;, &quot;temp.diurnal.range&quot;, &quot;temp.seasonality&quot;, &quot;precip.warm.qtr&quot;, &quot;precip.seasonality&quot;, &quot;precip.cold.qtr&quot;) That gets me a set of variables that are not so horribly correlated. tmpdat &lt;- dat.und[, envvars] varCor &lt;- cor(tmpdat, use = &quot;na.or.complete&quot;) corrplot::corrplot(varCor) And the variance inflation factors look ok. usdm::vif(tmpdat) Variables VIF 1 mean.temp 5.230313 2 temp.diurnal.range 1.841852 3 temp.seasonality 4.478608 4 precip.warm.qtr 5.664779 5 precip.seasonality 5.954538 6 precip.cold.qtr 5.980539 plot(allVars[[envvars]]) 6.3 Variance Inflation Factor As an experiment, I will use variable inflation to select a set of non-correlated variables. This doesn’t try to use any biological reasoning about limiting factors for Trillium. It is just a statistical method to chose a set of uncorrelated variables. vifres &lt;- usdm::vifstep(subset(dat.und, select = c(-pa, -lon, -lat))) vifvars &lt;- as.character(vifres@results$Variables) vifvars [1] &quot;temp.diurnal.range&quot; &quot;temp.seasonality&quot; [3] &quot;mean.temp.warm.qtr&quot; &quot;precip.seasonality&quot; [5] &quot;precip.warm.qtr&quot; &quot;precip.cold.qtr&quot; [7] &quot;slope&quot; &quot;aspect&quot; [9] &quot;Evergreen.Broadleaf.Trees&quot; &quot;Mixed.Other.Trees&quot; [11] &quot;Shrubs&quot; &quot;Herbaceous&quot; [13] &quot;Cultivated&quot; &quot;Flooded&quot; [15] &quot;Urban&quot; &quot;Barren&quot; [17] &quot;Water&quot; 6.4 Save I’ll test models with all variables and these subsets. topovars &lt;- c(&quot;elevation&quot;, &quot;slope&quot;, &quot;aspect&quot;) lcvars &lt;- c(&quot;Tree.Cover&quot;, &quot;mean.temp&quot;, &quot;precip.warm.qtr&quot;) envvars &lt;- c(&quot;mean.temp&quot;, &quot;temp.diurnal.range&quot;, &quot;temp.seasonality&quot;, &quot;precip.warm.qtr&quot;, &quot;precip.seasonality&quot;, &quot;precip.cold.qtr&quot;) minEnvVars &lt;- c(&quot;precip.warm.qtr&quot;, &quot;mean.temp&quot;, &quot;temp.diurnal.range&quot;) I’ll save because I’ll be using these variables across different SDM chapters. save(topovars, lcvars, envvars, minEnvVars, vifvars, file = &quot;data/varlists.RData&quot;) "],
["training-and-testing-data.html", "Chapter 7 Training and Testing Data 7.1 Presence train/test 7.2 Background train/test 7.3 Training data 7.4 Create many datasets 7.5 Save", " Chapter 7 Training and Testing Data Our dat, dat.und and dat.grand data frames have all our data. But when we fit models to data, we need to hold out some data for testing the fit. This is also called cross-validation. The jargon used is folds where each fold is the random sample of data that you will test against. So if we do k-fold cross-validation where k=5. That means we randomly assign our data to 5 groups (1 to 5). We do 5 fits. The first one will use group 1 as the testing data, and fit the model to the other data. The second one will use group 2 as the testing data and fit to the rest. Etc. That ensure that you test against different data each time. Another way to do this test is to randomly select 1/k proportion of your data to use for testing and repeat that many times to create many test/train data sets. I am going to use this approach. This chapter will use the following libraries. library(dismo) Load the data. This will output the names that are loaded. datnames &lt;- load(&quot;data/trillium_with_predictors.RData&quot;) 7.1 Presence train/test We set up a training set of presence data and a test set. kfold is just a function to randomly assign the data to k groups. I want just the presence data so will subset to pa column equal 1. I will call the presence only data presdat. set.seed(10) presdat &lt;- subset(dat.und, pa == 1) group &lt;- dismo::kfold(presdat, k = 5) # 5 groups = 20 test/80 train split The testing data will be group==1 and training data will be the rest. pres_train &lt;- presdat[group != 1, ] pres_test &lt;- presdat[group == 1, ] 7.2 Background train/test We repeat the process above for the background data (the pa=0). bgdat &lt;- subset(dat.und, pa == 0) group &lt;- dismo::kfold(bgdat, k = 5) backg_train &lt;- bgdat[group != 1, ] backg_test &lt;- bgdat[group == 1, ] 7.3 Training data We make separate presence and background train/test sets for evaluation purposes later. But for fitting we need a data frame with both train data sets (presence and background) together. traindat &lt;- rbind(pres_train, backg_train) 7.4 Create many datasets The above code would create just one dataset, but we want to create many since we want to see how/if the model changes with a different training set. I’ll create a list and save the data there. I will run through the code above and assign my train/test datasets to a list. I need to save traindat used in the model fitting and pres_test and backg_test used in the evaluation functions. traindatlist &lt;- list() n &lt;- 20 for (i in 1:n) { presdat &lt;- subset(dat.und, pa == 1) group &lt;- dismo::kfold(presdat, k = 5) # 5 groups = 20 test/80 train split pres_train &lt;- presdat[group != 1, ] pres_test &lt;- presdat[group == 1, ] bgdat &lt;- subset(dat.und, pa == 0) group &lt;- dismo::kfold(bgdat, k = 5) backg_train &lt;- bgdat[group != 1, ] backg_test &lt;- bgdat[group == 1, ] traindatlist[[i]] &lt;- list(traindat = rbind(pres_train, backg_train), pres_test = pres_test, backg_test = backg_test) } 7.5 Save I’ll add this to the trillium_with_predictors data file. save(datnames, traindatlist, file = &quot;data/trillium_with_predictors.RData&quot;) "]
]
